{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razvanmatisan/BSc+MSc/Master/IEinAI/Project/ieai-miniproject-context-mixing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"processing\"), \"..\")))\n",
    "import numpy as np\n",
    "import spacy\n",
    "from inflecteur import inflecteur\n",
    "import pickle\n",
    "import torch\n",
    "import string\n",
    "from transformers import WhisperProcessor, Wav2Vec2Processor\n",
    "from datasets import Dataset, Audio, load_dataset, concatenate_datasets\n",
    "from utils import det_words, irregular_nouns\n",
    "from utils import MODEL_PATH, DATA_KEY, TEXT_KEY\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razvanmatisan/BSc+MSc/Master/IEinAI/Project/ieai-miniproject-context-mixing/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TASK = \"common_voice\"\n",
    "SPLIT = \"test\" \n",
    "GENERATED_IDS_PATH = f\"./directory/predictions/{TASK}/{SPLIT}/\"\n",
    "ALIGNMENT_PATH = f\"./directory/mfa/common_voice/test/outputs/\"\n",
    "ANNOTATED_DATA_PATH = f\"./directory/datasets/{TASK}/{SPLIT}/\"\n",
    "\n",
    "# MODEL_TYPE = \"whisper-base\"\n",
    "\n",
    "MODEL_PATH = {\n",
    "    # 'whisper-tiny': 'openai/whisper-tiny',\n",
    "    'whisper-base': 'openai/whisper-base',\n",
    "    'whisper-small': 'openai/whisper-small',\n",
    "    # 'whisper-medium': 'openai/whisper-medium',\n",
    "    'wav2vec2-large-xlsr-53-french': 'jonatasgrosman/wav2vec2-large-xlsr-53-french',\n",
    "    # 'asr-wav2vec2-french': 'bhuang/asr-wav2vec2-french',\n",
    "}\n",
    "\n",
    "NUM_LAYERS = {\n",
    "    # 'whisper-tiny': 4,\n",
    "    'whisper-base': 6,\n",
    "    'whisper-small': 12,\n",
    "    # 'whisper-medium': 24,\n",
    "    'wav2vec2-large-xlsr-53-french': 24,\n",
    "    # 'asr-wav2vec2-french': 24,\n",
    "}\n",
    "\n",
    "DATA_KEY = {\n",
    "    \"common_voice\": \"mozilla-foundation/common_voice_11_0\",\n",
    "}\n",
    "TEXT_KEY = {\n",
    "    'common_voice': 'sentence',\n",
    "}\n",
    "\n",
    "PROCESSOR = {\n",
    "    'whisper-base': WhisperProcessor.from_pretrained(MODEL_PATH['whisper-base'], task='transcribe', language='french'),\n",
    "    'whisper-small': WhisperProcessor.from_pretrained(MODEL_PATH['whisper-small'], task='transcribe', language='french'),\n",
    "    # 'whisper-medium': WhisperProcessor.from_pretrained(MODEL_PATH['whisper-medium'], task='transcribe', language='french'),\n",
    "    'wav2vec2-large-xlsr-53-french': Wav2Vec2Processor.from_pretrained(MODEL_PATH['wav2vec2-large-xlsr-53-french']), \n",
    "    # 'asr-wav2vec2-french': Wav2Vec2Processor.from_pretrained(MODEL_PATH['asr-wav2vec2-french']), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\t dela-fr-public...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ANNOTATED_DATA_PATH):\n",
    "    os.makedirs(ANNOTATED_DATA_PATH)\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "inflecteur = inflecteur()\n",
    "inflecteur.load_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the original dataset and load the incorrectly predicted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOADING DATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/razvanmatisan/BSc+MSc/Master/IEinAI/Project/ieai-miniproject-context-mixing/.venv/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load original data\n",
    "print('DOWNLOADING DATA')\n",
    "org_data = load_dataset(DATA_KEY[TASK], 'fr', split=SPLIT, verification_mode=\"all_checks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENGTH = 5000\n",
    "LENGTH = len(org_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASTING FILES TO AUDIO\n"
     ]
    }
   ],
   "source": [
    "print('CASTING FILES TO AUDIO')\n",
    "org_data = org_data.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "\n",
    "# Load generated ids\n",
    "generated_ids = {}\n",
    "for model_name in MODEL_PATH.keys():\n",
    "    with open(f'{GENERATED_IDS_PATH}{model_name}/generated_ids.pkl', 'rb') as fp:\n",
    "        generated_ids[model_name] = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIGNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['total_start', 'total_end', 'intervals'],\n",
       "    num_rows: 16089\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ALIGNING\")\n",
    "file_ids = [int(f.split('.')[0]) for f in os.listdir(ALIGNMENT_PATH) if f.endswith('.TextGrid')]\n",
    "alignments = []\n",
    "\n",
    "for ex in range(LENGTH):\n",
    "    if ex not in file_ids:\n",
    "        alignments.append({'id': ex, 'total_start': None, 'total_end': None, 'intervals': None})           \n",
    "        continue\n",
    "    lines = open(f\"{ALIGNMENT_PATH}{ex}.TextGrid\", \"r\").readlines()\n",
    "    total_min = float(lines[3].strip().split()[2])\n",
    "    total_max = float(lines[4].strip().split()[2])\n",
    "    num_intervals = int(lines[13].strip().split('=')[-1])\n",
    "    intervals = []\n",
    "    for it in range(num_intervals):\n",
    "        xmin = float(lines[15+it*4].split(\"=\")[-1].strip())\n",
    "        xmax = float(lines[16+it*4].split(\"=\")[-1].strip())\n",
    "        text = lines[17+it*4].split(\"=\")[-1].strip()[1:-1]\n",
    "        if text != \"\":\n",
    "            intervals.append({'start': xmin, 'end': xmax, 'word': text})\n",
    "    alignments.append({'total_start': total_min, 'total_end': total_max, 'intervals': intervals})           \n",
    "alignments = Dataset.from_list(alignments)\n",
    "alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-base\n",
      "whisper-small\n",
      "wav2vec2-large-xlsr-53-french\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load incorrect sentences\n",
    "df = pd.read_csv(\"./directory/predictions/common_voice/test/whisper-base/annotated_cue_target.csv\")\n",
    "\n",
    "dfs = dict()\n",
    "\n",
    "for model_name in MODEL_PATH.keys():\n",
    "    dfs[model_name] = pd.read_csv(f\"./directory/predictions/common_voice/test/{model_name}/annotated_det_noun.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number samples whisper-base: 8\n",
      "Number samples whisper-small: 5\n",
      "Number samples wav2vec2-large-xlsr-53-french: 40\n"
     ]
    }
   ],
   "source": [
    "print(f'Number samples whisper-base: {len(dfs[\"whisper-base\"])}')\n",
    "print(f'Number samples whisper-small: {len(dfs[\"whisper-small\"])}')\n",
    "print(f'Number samples wav2vec2-large-xlsr-53-french: {len(dfs[\"wav2vec2-large-xlsr-53-french\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(processor, ex, cue_word, target_true, target_pred, model_name):\n",
    "    # find decoder indices\n",
    "    target_token_dec_indices = {}\n",
    "    cue_token_dec_indices = {}\n",
    "    # for model_name in MODEL_PATH.keys():\n",
    "\n",
    "    if model_name.split('-')[0] == \"whisper\":\n",
    "        # mapping subwords to words\n",
    "        generated_tokens = processor.tokenizer.convert_ids_to_tokens(generated_ids[model_name][ex].tolist())\n",
    "        generated_words = []\n",
    "        word_indices = []\n",
    "        current_word = -1\n",
    "        for token in generated_tokens:\n",
    "            if token.startswith(\"Ġ\") or token in ['<|fr|>', '<|transcribe|>', '<|notimestamps|>', '<|endoftext|>'] or token in string.punctuation or generated_words[-1] in string.punctuation:\n",
    "                generated_words.append(processor.tokenizer.convert_tokens_to_string(token).strip().lower() if token.startswith(\"Ġ\") else token.lower())\n",
    "                current_word += 1\n",
    "            else:\n",
    "                generated_words[-1] = generated_words[-1] + processor.tokenizer.convert_tokens_to_string(token).lower()\n",
    "            word_indices.append(current_word)\n",
    "        generated_words = np.array(generated_words)\n",
    "        # print(generated_words)\n",
    "        word_indices = np.array(word_indices)\n",
    "\n",
    "        # print(len(generated_words))\n",
    "\n",
    "        \n",
    "        # find target and cue token indices\n",
    "        target_word_indices = np.where(generated_words == target_pred.lower())[0]\n",
    "        cue_word_indices = np.where(generated_words == cue_word.lower())[0]\n",
    "\n",
    "        # temp_cue_word_indices = []\n",
    "        min_diff = 1000\n",
    "        if len(cue_word_indices) > 1:\n",
    "            for cue_word_idx in cue_word_indices:\n",
    "                if np.abs(cue_word_idx - target_word_indices[0]) < min_diff:\n",
    "                    min_diff = np.abs(cue_word_idx - target_word_indices[0])\n",
    "                    cue_word_indices = np.array([cue_word_idx])\n",
    "\n",
    "        # Multiple cues:\n",
    "        # cue word wouldn't come after the target word\n",
    "        cue_word_indices = cue_word_indices[cue_word_indices < np.max(target_word_indices)]\n",
    "        # if cue ids are not consecutive that means they are not splited tokens blong to one word. we have multiple same cues so the right cue is the one nearest to the target\n",
    "        while np.max(cue_word_indices) - np.min(cue_word_indices) > 1:\n",
    "            cue_word_indices = np.delete(cue_word_indices, np.where(cue_word_indices == np.min(cue_word_indices)))\n",
    "        # Multiple targets:\n",
    "        target_word_indices = target_word_indices[target_word_indices > np.min(cue_word_indices)]\n",
    "        while np.max(target_word_indices) - np.min(target_word_indices) > 1:\n",
    "            target_word_indices = np.delete(target_word_indices, np.where(target_word_indices == np.max(target_word_indices)))\n",
    "\n",
    "        # check if there are many\n",
    "        if len(target_word_indices) > 1:\n",
    "            print(\"multiple target words error\")\n",
    "            # continue\n",
    "        if len(cue_word_indices) > 1:\n",
    "            print(\"multiple cue words error\")\n",
    "            # continue\n",
    "        target_token_dec_indices[model_name] = np.where(word_indices == target_word_indices)[0].tolist()\n",
    "        cue_token_dec_indices[model_name] = np.where(word_indices == cue_word_indices)[0].tolist()\n",
    "    else:\n",
    "        # wav2vec based models do not have decoder part\n",
    "        target_token_dec_indices[model_name] = None\n",
    "        cue_token_dec_indices[model_name] = None\n",
    "\n",
    "    # find encoder indices\n",
    "    aligned_enc_words = [alignments[ex]['intervals'][i]['word'].lower() for i in range(len(alignments[ex]['intervals']))]\n",
    "    target_word_enc_indices = np.where(np.isin(np.array(aligned_enc_words), np.array(target_true.lower())))[0]\n",
    "    cue_word_enc_indices = np.where(np.isin(np.array(aligned_enc_words), np.array(cue_word.lower())))[0]\n",
    "\n",
    "    min_diff = 1000\n",
    "    if len(cue_word_enc_indices) > 1:\n",
    "        for cue_word_idx in cue_word_enc_indices:\n",
    "            if np.abs(cue_word_idx - target_word_enc_indices[0]) < min_diff:\n",
    "                min_diff = np.abs(cue_word_idx - target_word_enc_indices[0])\n",
    "                cue_word_enc_indices = np.array([cue_word_idx])\n",
    "\n",
    "    # Multiple Cues\n",
    "    # cue word wouldn't come after the target word\n",
    "    cue_word_enc_indices = cue_word_enc_indices[cue_word_enc_indices < np.max(target_word_enc_indices)]\n",
    "    # if cue ids are not consecutive that means they are not splited tokens blong to one word. we have multiple same cues so the right cue is the one nearest to the target\n",
    "    while np.max(cue_word_enc_indices) - np.min(cue_word_enc_indices) > 1:\n",
    "        cue_word_enc_indices = np.delete(cue_word_enc_indices, np.where(cue_word_enc_indices == np.min(cue_word_enc_indices)))\n",
    "    # Multiple Targets\n",
    "    target_word_enc_indices = target_word_enc_indices[target_word_enc_indices > np.min(cue_word_enc_indices)]\n",
    "    while np.max(target_word_enc_indices) - np.min(target_word_enc_indices) > 1:\n",
    "        target_word_enc_indices = np.delete(target_word_enc_indices, np.where(target_word_enc_indices == np.max(target_word_enc_indices)))\n",
    "    \n",
    "    cue_word_enc_indices = cue_word_enc_indices.tolist()\n",
    "    target_word_enc_indices = target_word_enc_indices.tolist()\n",
    "\n",
    "    return cue_token_dec_indices, target_token_dec_indices, cue_word_enc_indices, target_word_enc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper-base\n",
      "Les chips tortillas sont l’apéritif le plus typique des cuisines tex-mex et mexicaine.\n",
      "Mais la natures est toujours là, omniprésente.\n",
      "Cependant, l'échange est annulé après que Reynolds ait échoué les tests médicaux des Colts.\n",
      "Il laisse également de nombreuses lettres, des vies de saints, et des poèmes.\n",
      "Le fonds d'origine inclut des manuscrits de Marc-Antoine Charpentier et de Jean-Jacques Rousseau.\n",
      "Mais la fille veut des princesses et le garçon des monstres.\n",
      "Les brise-lames sont les chevaux de frise des fortifications contre les tempêtes.\n",
      "La vigne, avec ses nouveaux plans couvre de plus en plus de surface.\n",
      "whisper-small\n",
      "Les tarses sont rose carmin.\n",
      "Mais la natures est toujours là, omniprésente.\n",
      "Les habitants se nomment les Trouille-Bourreaux.\n",
      "À repère égal, les crues qu'il signale sont donc moins graves.\n",
      "En son sein, nous avons tous les mêmes droits et les mêmes devoirs.\n",
      "wav2vec2-large-xlsr-53-french\n",
      "Et quelques mariages.\n",
      "Maximiliano Richeze et Roberto Ferrari sont les équipiers de Modolo pour les sprints.\n",
      "Des physiciens ont alors cherché à étendre ce groupe.\n",
      "Tous les planchers sont en bois dur.\n",
      "Les joueurs fantômes peuvent incarner différentes parties du monstre final pour contrer le héros.\n",
      "Les investissements ont inclus les grandes exploitations agricoles et le développement des ressources naturelles.\n",
      "Ils jouent leur matchs à domicile au Parramatta Stadium.\n",
      "Les Suédoises s’arrêtent au stade des quarts de finale contre les Allemandes.\n",
      "Les amendements numéros quatre cent soixante rectifié et mille cinq cents rectifié sont identiques.\n",
      "Chacun de ces deux cercles avaient créé un prix littéraire récompensant un ouvrage historique.\n",
      "Des malformations comme celles du pourceau de Landser intéressaient les hommes depuis des siècles.\n",
      "C'est le de champion de République tchèque de l'histoire du Sparta.\n",
      "Son électronique est en constante évolution grâce aux recherche par les étudiants et ingénieurs.\n",
      "Il y a plusieurs mésententes entre des colons et des propriétaires britanniques.\n",
      "Ils sont assassinés un par un par tirs de mitraillette.\n",
      "Aucun vestiges ne subsiste des deux niveaux et du système de couverture primitifs.\n",
      "Il fait l’objet d’une acquisition par le Fonds national d'art contemporain.\n",
      "Les villas Markelius ont toutes deux suscité l'intérêt de la communauté architecturale internationale.\n",
      "Une deuxième difficulté se présente.\n",
      "Le port du dos est horizontal et l'allure ramassée.\n",
      "Aucun des chiens ne l’écoutait.\n",
      "Elle représente une grande et puissante unité de l'arme blindée et cavalerie.\n",
      "Il avait lieu sur le circuit d'Imola.\n",
      "Le pari technique était audacieux.\n",
      "Ils enlèvent leurs patins et les sanglent aux pieds du malheureux.\n",
      "Les préhistoriens estiment que les Gadsup habitent leurs terres depuis plusieurs milliers d'années.\n",
      "Les jokers sont présents tout au long du jeu pour aider les candidats.\n",
      "Tous les multiplex sont maintenant diffusés depuis le sommet de l’émetteur.\n",
      "Elles sont à apporter un oui quasi-unanime.\n",
      "Les matchs se sont joués en plein air sur gazon.\n",
      "Ceci permet d'équilibrer les scores entre joueurs de niveau différent.\n",
      "Cela entraîne une concentration sanguine en phénylalanine trop élevée chez l'individu malade.\n",
      "Elle doit notamment préparer le fonds pour une réouverture de ce musée.\n",
      "Les recommandations de Veoh sont basées sur le comportement de l'utilisateur.\n",
      "Beaucoup de ses ouvrages se trouvent dans le Fonds Grandidier à Antananarivo, Madagascar.\n",
      "Le soleil à son déclin empourpre l'horizon.\n",
      "Les vis de la serrure sautèrent bientôt.\n",
      "Seuls les jingles et les coupures pubs sont différents.\n",
      "Matt Jones dessina les symboles et publia un document sur Internet les contenants tous.\n",
      "Les combattants réunis sont menés par le Pakistanais Assim Omar.\n"
     ]
    }
   ],
   "source": [
    "det_noun_data = {\"whisper-base\": [], \"whisper-small\": [], \"wav2vec2-large-xlsr-53-french\": []}\n",
    "\n",
    "for model_name in MODEL_PATH.keys():\n",
    "    print(model_name)\n",
    "    for _, row in dfs[model_name].iterrows():\n",
    "        id = row[\"id\"]\n",
    "        target_true = row['target_true']\n",
    "        target_pred = row['target_pred']\n",
    "        cue = row['cue']\n",
    "\n",
    "        if alignments[id]['intervals'] is None:\n",
    "            continue\n",
    "        \n",
    "        sentence = org_data['sentence'][id]\n",
    "        print(sentence)\n",
    "\n",
    "        if sentence.startswith('\"') and sentence.endswith('\"'):\n",
    "            sentence = sentence[1:-1]\n",
    "\n",
    "        doc = nlp(sentence)\n",
    "        word_list = [word.text for word in doc]\n",
    "        dep_list = [word.dep_ for word in doc]\n",
    "\n",
    "        # filter if target or cue words have not been founded by aligner\n",
    "        aligned_words = [alignments[id]['intervals'][i]['word'].lower() for i in range(len(alignments[id]['intervals']))]\n",
    "\n",
    "        if cue.lower() not in aligned_words or target_true.lower() not in aligned_words:\n",
    "            continue\n",
    "\n",
    "        cue_token_dec_indices, target_token_dec_indices, cue_word_enc_indices, target_word_enc_indices = find_indices(PROCESSOR[model_name], id, cue, target_true, target_pred, model_name)\n",
    "        \n",
    "        labels = {'number': 'number',\n",
    "            'person': 'person',\n",
    "            'tense': 'tense'}\n",
    "\n",
    "        det_noun_data[model_name].append({\n",
    "            'template': 'det_noun',\n",
    "            'org_id': id, \n",
    "            'text': sentence, \n",
    "            'cue_word': cue,\n",
    "            'target_word': target_pred,\n",
    "            'target_word_2': None,\n",
    "            'path': org_data[id]['path'],\n",
    "            'audio': org_data[id]['audio'],\n",
    "            'alignment': alignments[id],\n",
    "            'target_indices': {'enc': target_word_enc_indices, 'dec': target_token_dec_indices},\n",
    "            'cue_indices': {'enc': cue_word_enc_indices, 'dec': cue_token_dec_indices},\n",
    "            'target_indices_2': None,\n",
    "            'label_number': labels['number'],\n",
    "            'label_person': labels['person'],\n",
    "            'label_tense': labels['tense'],\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "# org_data[\"sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating homophony dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_noun_data = det_noun(org_data[TEXT_KEY[TASK]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 8/8 [00:00<00:00, 1170.82 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 858.47 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 37/37 [00:00<00:00, 2105.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# det_noun_data\n",
    "\n",
    "for model_name in MODEL_PATH.keys():\n",
    "    det_noun_data[model_name] = Dataset.from_list(det_noun_data[model_name])\n",
    "    det_noun_data[model_name].save_to_disk(f\"{ANNOTATED_DATA_PATH}{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
